{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# reset gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramerers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# '''train'''\n",
    "# parser.add_argument(\"--max_lr\", default=3e-4, type=float)\n",
    "# parser.add_argument(\"--wd\", default=1e-5, type=float)\n",
    "# parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "# parser.add_argument(\"--run_name\", default=None, type=Path)\n",
    "# parser.add_argument('--loss_type', default=\"label_smooth\", type=str)\n",
    "# parser.add_argument('--n_epochs', default=3500, type=int)\n",
    "# parser.add_argument('--epoch_mix', default=12, type=int)\n",
    "# parser.add_argument(\"--amp\", action='store_true')\n",
    "# parser.add_argument(\"--filter_bias_and_bn\", action='store_true', default=True)\n",
    "# parser.add_argument(\"--ext_pretrained\", default=None, type=str)\n",
    "# parser.add_argument(\"--multilabel\", action='store_true')\n",
    "# parser.add_argument('--save_path', default=None, type=Path)\n",
    "# parser.add_argument('--load_path', default=None, type=Path)\n",
    "# parser.add_argument('--scheduler', default=None, type=str)\n",
    "# parser.add_argument('--augs_signal', nargs='+', type=str,\n",
    "#                     default=['amp', 'neg', 'tshift', 'tmask', 'ampsegment', 'cycshift'])\n",
    "# parser.add_argument('--augs_noise', nargs='+', type=str,\n",
    "#                     default=['awgn', 'abgn', 'apgn', 'argn', 'avgn', 'aun', 'phn', 'sine'])\n",
    "# parser.add_argument('--augs_mix', nargs='+', type=str, default=['mixup', 'timemix', 'freqmix', 'phmix'])\n",
    "# parser.add_argument('--mix_loss', default='bce', type=str)\n",
    "# parser.add_argument('--mix_ratio', default=1, type=float)\n",
    "# parser.add_argument('--ema', default=0.995, type=float)\n",
    "# parser.add_argument('--log_interval', default=100, type=int)\n",
    "# parser.add_argument(\"--kd_model\", default=None, type=Path)\n",
    "# parser.add_argument(\"--use_bg\", action='store_true', default=False)\n",
    "# parser.add_argument(\"--resume_training\", action='store_true', default=False)\n",
    "# parser.add_argument(\"--use_balanced_sampler\", action='store_true', default=False)\n",
    "# '''common'''\n",
    "# parser.add_argument('--local_rank', default=0, type=int)\n",
    "# parser.add_argument('--gpu_ids', nargs='+', default=[0])\n",
    "# parser.add_argument(\"--use_ddp\", action='store_true')\n",
    "# parser.add_argument(\"--use_dp\", action='store_true')\n",
    "# parser.add_argument('--save_interval', default=100, type=int)\n",
    "# '''data'''\n",
    "# parser.add_argument('--fold_id', default=1, type=int)\n",
    "# parser.add_argument(\"--data_subtype\", default='balanced', type=str)\n",
    "# parser.add_argument('--seq_len', default=90112, type=int)\n",
    "# parser.add_argument('--dataset', default=\"urban8k\", type=str)\n",
    "# parser.add_argument('--n_classes', default=50, type=int)\n",
    "# '''net'''\n",
    "# parser.add_argument('--ds_factors', nargs='+', type=int, default=[4, 4, 4, 4])\n",
    "# parser.add_argument('--n_head', default=8, type=int)\n",
    "# parser.add_argument('--n_layers', default=4, type=int)\n",
    "# parser.add_argument(\"--emb_dim\", default=128, type=int)\n",
    "# parser.add_argument(\"--model_type\", default='SoundNetRaw', type=str)\n",
    "# parser.add_argument(\"--nf\", default=16, type=int)\n",
    "# parser.add_argument(\"--dim_feedforward\", default=512, type=int)\n",
    "# parser.add_argument(\"--sampling_rate\", default=22050, type=int)\n",
    "# '''system'''\n",
    "# parser.add_argument('--data_dir', default='data/', type=Path)\n",
    "# parser.add_argument('--gpus', type=list, default=[0])\n",
    "# parser.add_argument('--num_workers', type=int, default=16)\n",
    "# args = parser.parse_args(args=[])\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "'''train'''\n",
    "parser.add_argument(\"--max_lr\", default=3e-4, type=float)\n",
    "parser.add_argument(\"--wd\", default=1e-5, type=float)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--run_name\", default=None, type=Path)\n",
    "parser.add_argument('--loss_type', default=\"label_smooth\", type=str)\n",
    "parser.add_argument('--n_epochs', default=None, type=int)\n",
    "parser.add_argument('--epoch_mix', default=None, type=int)\n",
    "parser.add_argument(\"--amp\", action='store_true')\n",
    "parser.add_argument(\"--filter_bias_and_bn\", action='store_true', default=True)\n",
    "parser.add_argument(\"--ext_pretrained\", default=None, type=str)\n",
    "parser.add_argument(\"--multilabel\", action='store_true')\n",
    "parser.add_argument('--save_path', default=None, type=Path)\n",
    "parser.add_argument('--load_path', default=None, type=Path)\n",
    "parser.add_argument('--scheduler', default=None, type=str)\n",
    "parser.add_argument('--augs_signal', nargs='+', type=str,\n",
    "                    default=['amp', 'neg', 'tshift', 'tmask', 'ampsegment', 'cycshift'])\n",
    "parser.add_argument('--augs_noise', nargs='+', type=str,\n",
    "                    default=['awgn', 'abgn', 'apgn', 'argn', 'avgn', 'aun', 'phn', 'sine'])\n",
    "# parser.add_argument('--augs_signal', nargs='+', type=str,\n",
    "#                     default=[])\n",
    "# parser.add_argument('--augs_noise', nargs='+', type=str,\n",
    "#                     default=[])\n",
    "parser.add_argument('--augs_mix', nargs='+', type=str, default=['mixup', 'timemix', 'freqmix', 'phmix'])\n",
    "parser.add_argument('--mix_loss', default='bce', type=str)\n",
    "parser.add_argument('--mix_ratio', default=1, type=float)\n",
    "parser.add_argument('--ema', default=0.995, type=float)\n",
    "parser.add_argument('--log_interval', default=100, type=int)\n",
    "parser.add_argument(\"--kd_model\", default=None, type=Path)\n",
    "parser.add_argument(\"--use_bg\", action='store_true', default=False)\n",
    "parser.add_argument(\"--resume_training\", action='store_true', default=False)\n",
    "parser.add_argument(\"--use_balanced_sampler\", action='store_true', default=False)\n",
    "'''common'''\n",
    "parser.add_argument('--local_rank', default=0, type=int)\n",
    "parser.add_argument('--gpu_ids', nargs='+', default=[0])\n",
    "parser.add_argument(\"--use_ddp\", action='store_true')\n",
    "parser.add_argument(\"--use_dp\", action='store_true')\n",
    "parser.add_argument('--save_interval', default=100, type=int)\n",
    "'''data'''\n",
    "parser.add_argument('--fold_id', default=1, type=int)\n",
    "parser.add_argument(\"--data_subtype\", default='balanced', type=str)\n",
    "parser.add_argument('--seq_len', default=90112, type=int)\n",
    "parser.add_argument('--dataset', default=\"esc50\", type=str)\n",
    "parser.add_argument('--n_classes', default=50, type=int)\n",
    "'''net'''\n",
    "parser.add_argument('--ds_factors', nargs='+', type=int, default=[4, 4, 4, 4])\n",
    "parser.add_argument('--n_head', default=8, type=int)\n",
    "parser.add_argument('--n_layers', default=4, type=int)\n",
    "parser.add_argument(\"--emb_dim\", default=128, type=int)\n",
    "parser.add_argument(\"--model_type\", default='SoundNetRaw', type=str)\n",
    "parser.add_argument(\"--nf\", default=16, type=int)\n",
    "parser.add_argument(\"--dim_feedforward\", default=512, type=int)\n",
    "parser.add_argument(\"--sampling_rate\", default=22050, type=int)\n",
    "'''system'''\n",
    "parser.add_argument('--data_dir', default='data/', type=Path)\n",
    "parser.add_argument('--data_path', default='/workspace/data/ESC-50-master', type=str)\n",
    "\n",
    "parser.add_argument('--gpus', type=list, default=[0])\n",
    "parser.add_argument('--num_workers', type=int, default=30)\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESC50 Dataset\n",
    "The ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.\n",
    "\n",
    "The dataset consists of 5-second-long recordings organized into 50 semantical classes.\n",
    "[Github](https://github.com/karolpiczak/ESC-50)\n",
    "\n",
    "[Huggingface](https://huggingface.co/datasets/ashraq/esc50) \"ashraq/esc50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "Prepare your dataset. All code that only need to be executed ones before training and results fit on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 345/345 [00:00<00:00, 297kB/s]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading metadata: 100%|██████████| 1.61k/1.61k [00:00<00:00, 1.37MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [00:20<00:00, 19.0MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [01:23<00:00, 4.64MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [01:43<00:00, 103.66s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 678.25it/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:01<00:00, 1223.16 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:15<00:00, 130.93 examples/s]\n",
      "Saving the dataset (3/3 shards): 100%|██████████| 2000/2000 [00:00<00:00, 2990.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "def preprocess_audio(example):\n",
    "    audio = example['audio']\n",
    "    audio = audio['array']\n",
    "    if audio.shape[0] >= args.seq_len:\n",
    "        max_audio_start = audio.shape[0] - args.seq_len\n",
    "        audio_start = random.randint(0, max_audio_start)\n",
    "        audio = audio[audio_start : audio_start + args.seq_len]\n",
    "    else:\n",
    "        audio = F.pad(\n",
    "            audio, (0, args.seq_len - audio.size(0)), \"constant\"\n",
    "        ).data\n",
    "    example['audio'] = audio\n",
    "    return example\n",
    "\n",
    "esc50 = load_dataset(\"ashraq/esc50\", cache_dir=args.data_dir)\n",
    "esc50 = esc50.cast_column(\"audio\", Audio(sampling_rate=args.sampling_rate))\n",
    "# rename column target to label\n",
    "esc50 = esc50.rename_column(\"target\", \"label\")\n",
    "esc50 = esc50.map(preprocess_audio)\n",
    "esc50.save_to_disk(os.path.join(args.data_dir, 'esc50processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import Audio\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from workspace.datasets.audio_augs import AudioAugs\n",
    "\n",
    "\n",
    "\n",
    "def train_transform(batch):\n",
    "    transforms = args.augs_signal + args.augs_noise\n",
    "    audio = torch.Tensor(batch['audio'])\n",
    "    if transforms is not None:\n",
    "        # check if audio has more then 1 dimension\n",
    "        if len(audio.shape) > 1:\n",
    "            # iterate over all dimensions\n",
    "            for i in range(audio.shape[0]):\n",
    "                audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i])\n",
    "        else:\n",
    "            batch['audio'] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio)      \n",
    "    batch['audio'] = audio.unsqueeze(1)\n",
    "    batch['label'] = torch.Tensor(batch['label']).long()\n",
    "    return batch\n",
    "\n",
    "def gpu_transforms(batch):\n",
    "    transforms = args.augs_signal + args.augs_noise\n",
    "    audio = batch['audio']\n",
    "    if transforms is not None:\n",
    "        # check if audio has more then 1 dimension\n",
    "        if len(audio.shape) > 1:\n",
    "            # iterate over all dimensions\n",
    "            for i in range(audio.shape[0]):\n",
    "                audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i][0])\n",
    "        else:\n",
    "            batch['audio'] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio)      \n",
    "    batch['audio'] = audio\n",
    "    return batch\n",
    "    \n",
    "def test_transform(batch):\n",
    "    batch['audio'] = torch.Tensor(batch['audio']).unsqueeze(1)\n",
    "    batch['label'] = torch.Tensor(batch['label']).long()\n",
    "    return batch\n",
    "\n",
    "class ESC50DataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: Path = args.data_dir):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    # called only within a single process on CPU but everytime trainer is envoked\n",
    "    # def prepare_data(self):\n",
    "\n",
    "    # run on each GPU\n",
    "    def setup(self, stage: str):\n",
    "        # load from disk\n",
    "        esc50 = load_from_disk(os.path.join(self.data_dir, 'esc50processed'))\n",
    "        esc50 = esc50.remove_columns(['filename', 'fold', 'category', 'esc10', 'src_file', 'take'])\n",
    "        # split into train, val, test\n",
    "        esc50 = esc50['train'].train_test_split(test_size=0.2, shuffle=True)\n",
    "        self.dataset_train = esc50['train']\n",
    "        # self.dataset_train = esc50['train'].with_format('torch', columns=['audio', 'label'])\n",
    "        self.dataset_test = esc50['test'].with_format('torch', columns=['audio', 'label'])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.dataset_train.set_transform(train_transform)\n",
    "        # self.dataset_train.set_transform(test_transform)\n",
    "        return DataLoader(self.dataset_train, batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        # generator=torch.Generator(device='cuda')\n",
    "        )\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.dataset_test.set_transform(test_transform)\n",
    "        return DataLoader(self.dataset_test, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        )\n",
    "    \n",
    "    # def on_after_batch_transfer(self, batch, dataloader_idx):\n",
    "    #     if self.trainer.training:\n",
    "    #         batch = gpu_transforms(batch)\n",
    "    #     return batch\n",
    "\n",
    "datamodule = ESC50DataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio\n\u001b[0;32m----> 3\u001b[0m esc50 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mashraq/esc50\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m esc50 \u001b[39m=\u001b[39m esc50\u001b[39m.\u001b[39mcast_column(\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m, Audio(sampling_rate\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39msampling_rate))\n\u001b[1;32m      5\u001b[0m \u001b[39m# split into train, val, test\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py:2136\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2133\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2135\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2136\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   2137\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2138\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2139\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   2140\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   2141\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   2142\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2143\u001b[0m )\n\u001b[1;32m   2145\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   2147\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   2148\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 954\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    955\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    956\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    957\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    958\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:1027\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[1;32m   1026\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1027\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m   1029\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/parquet/parquet.py:34\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files:\n\u001b[1;32m     33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m data_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_files)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_files, (\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m     36\u001b[0m     files \u001b[39m=\u001b[39m data_files\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:564\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[1;32m    549\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(url_or_urls))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:427\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    424\u001b[0m download_func \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[1;32m    426\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m--> 427\u001b[0m downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[1;32m    428\u001b[0m     download_func,\n\u001b[1;32m    429\u001b[0m     url_or_urls,\n\u001b[1;32m    430\u001b[0m     map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    431\u001b[0m     num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[1;32m    432\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_progress_bar_enabled(),\n\u001b[1;32m    433\u001b[0m     desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    435\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    436\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:463\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    461\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[0;32m--> 463\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    465\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    466\u001b[0m     ]\n\u001b[1;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     mapped \u001b[39m=\u001b[39m parallel_map(function, iterable, num_proc, types, disable_tqdm, desc, _single_map_nested)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:464\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    461\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m    463\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 464\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    465\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    466\u001b[0m     ]\n\u001b[1;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     mapped \u001b[39m=\u001b[39m parallel_map(function, iterable, num_proc, types, disable_tqdm, desc, _single_map_nested)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:383\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[1;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[1;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    385\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:383\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[1;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[1;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    385\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:366\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    368\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:453\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    451\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    181\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    183\u001b[0m         url_or_filename,\n\u001b[1;32m    184\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    185\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    186\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    187\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    188\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    189\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    190\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    191\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    192\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m    193\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[1;32m    194\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    195\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    198\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:642\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[1;32m    640\u001b[0m     ftp_get(url, temp_file)\n\u001b[1;32m    641\u001b[0m \u001b[39melif\u001b[39;00m scheme \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 642\u001b[0m     fsspec_get(url, temp_file, storage_options\u001b[39m=\u001b[39;49mstorage_options, desc\u001b[39m=\u001b[39;49mdownload_desc)\n\u001b[1;32m    643\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     http_get(\n\u001b[1;32m    645\u001b[0m         url,\n\u001b[1;32m    646\u001b[0m         temp_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    652\u001b[0m         desc\u001b[39m=\u001b[39mdownload_desc,\n\u001b[1;32m    653\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:367\u001b[0m, in \u001b[0;36mfsspec_get\u001b[0;34m(url, temp_file, storage_options, desc)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGET can be called with at most one path but was called with \u001b[39m\u001b[39m{\u001b[39;00mpaths\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m callback \u001b[39m=\u001b[39m TqdmCallback(\n\u001b[1;32m    360\u001b[0m     tqdm_kwargs\u001b[39m=\u001b[39m{\n\u001b[1;32m    361\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdesc\u001b[39m\u001b[39m\"\u001b[39m: desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDownloading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m     }\n\u001b[1;32m    366\u001b[0m )\n\u001b[0;32m--> 367\u001b[0m fs\u001b[39m.\u001b[39;49mget_file(paths[\u001b[39m0\u001b[39;49m], temp_file\u001b[39m.\u001b[39;49mname, callback\u001b[39m=\u001b[39;49mcallback)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/spec.py:863\u001b[0m, in \u001b[0;36mAbstractFileSystem.get_file\u001b[0;34m(self, rpath, lpath, callback, outfile, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[39mwhile\u001b[39;00m data:\n\u001b[0;32m--> 863\u001b[0m     data \u001b[39m=\u001b[39m f1\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocksize)\n\u001b[1;32m    864\u001b[0m     segment_len \u001b[39m=\u001b[39m outfile\u001b[39m.\u001b[39mwrite(data)\n\u001b[1;32m    865\u001b[0m     \u001b[39mif\u001b[39;00m segment_len \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/spec.py:1703\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1701\u001b[0m     \u001b[39m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1703\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49m_fetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc \u001b[39m+\u001b[39;49m length)\n\u001b[1;32m   1704\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[1;32m   1705\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/caching.py:157\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    155\u001b[0m     part \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, end \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize)\n\u001b[0;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher(start, end)  \u001b[39m# new block replaces old\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m=\u001b[39m start\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_file_system.py:404\u001b[0m, in \u001b[0;36mHfFileSystemFile._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    397\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[1;32m    398\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrange\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    399\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39m_build_hf_headers(),\n\u001b[1;32m    400\u001b[0m }\n\u001b[1;32m    401\u001b[0m url \u001b[39m=\u001b[39m (\n\u001b[1;32m    402\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mREPO_TYPES_URL_PREFIXES\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrepo_type,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m/resolve/\u001b[39m\u001b[39m{\u001b[39;00msafe_quote(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrevision)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00msafe_quote(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mpath_in_repo)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m )\n\u001b[0;32m--> 404\u001b[0m r \u001b[39m=\u001b[39m http_backoff(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    405\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    406\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py:258\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:535\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    530\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    531\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    532\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    533\u001b[0m }\n\u001b[1;32m    534\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 535\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    537\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:648\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    647\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 648\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    650\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    440\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    441\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    442\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    443\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    444\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    445\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    449\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:665\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    664\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    666\u001b[0m     conn,\n\u001b[1;32m    667\u001b[0m     method,\n\u001b[1;32m    668\u001b[0m     url,\n\u001b[1;32m    669\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    670\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    671\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    672\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:421\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    416\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    417\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    419\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    420\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    422\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    417\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    419\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    420\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "esc50 = load_dataset(\"ashraq/esc50\")\n",
    "esc50 = esc50.cast_column(\"audio\", Audio(sampling_rate=args.sampling_rate))\n",
    "# split into train, val, test\n",
    "esc50 = esc50['train'].train_test_split(test_size=0.2, shuffle=True)\n",
    "esc50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datamodule.dataset_train\n",
    "tousand  = ds[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 1, 90112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': tensor([10, 34, 27, 13, 31,  3, 46, 10, 27, 35, 46,  8, 29, 21, 23, 26,  9, 27,\n",
       "         21, 29, 49, 37, 43,  0, 10, 49,  8, 12, 17, 46, 38, 30, 45, 48, 37, 38,\n",
       "         43, 28, 38,  0, 42, 42,  6, 44, 12, 19, 18, 43, 40, 15, 40, 23, 14, 30,\n",
       "         40, 29, 29, 42, 26, 38,  2, 26,  5, 17, 16, 22, 26, 22,  4,  6, 37, 47,\n",
       "         41, 19,  1, 44,  6, 18, 31, 42,  5, 47, 11, 14, 14, 15, 40,  3, 28, 37,\n",
       "         42,  4, 18, 25, 47,  5,  3, 23, 13, 29, 18, 27, 40, 43, 48,  0, 45, 44,\n",
       "          7, 18, 47, 32, 37, 28, 48, 25, 31, 47, 17, 11, 11, 44, 24, 34,  5, 13,\n",
       "         21,  4]),\n",
       " 'audio': tensor([[[-2.4267e-02, -2.1926e-02,  3.2290e-02,  ..., -5.1691e-02,\n",
       "            3.6324e-02,  6.2648e-02]],\n",
       " \n",
       "         [[-1.3261e-04,  5.6826e-05, -1.0920e-04,  ...,  5.3755e-04,\n",
       "            1.6293e-03,  1.1264e-03]],\n",
       " \n",
       "         [[-8.5173e-04,  3.7680e-03,  2.0799e-03,  ...,  7.0006e-04,\n",
       "            7.6404e-04,  7.2768e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.0162e-03,  2.8993e-03,  3.5582e-03,  ...,  9.7644e-05,\n",
       "            8.1677e-04,  1.4221e-03]],\n",
       " \n",
       "         [[-7.4635e-04, -8.8325e-04, -1.0269e-03,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-3.4700e-02, -2.7361e-02, -1.7656e-02,  ..., -2.3207e-02,\n",
       "           -3.3778e-02, -3.9267e-02]]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = datamodule.train_dataloader()\n",
    "batch = next(iter(dl))\n",
    "print(batch['label'].shape)\n",
    "print(batch['audio'].shape)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from workspace.datasets.batch_augs import BatchAugs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "ba_params = {\n",
    "        'seq_len': args.seq_len,\n",
    "        'fs': args.sampling_rate,\n",
    "        'augs': args.augs_mix,\n",
    "        'device': device,\n",
    "        'mix_ratio': args.mix_ratio,\n",
    "        'batch_sz': args.local_rank,\n",
    "        'epoch_mix': args.epoch_mix,\n",
    "        'resample_factors': [0.8, 0.9, 1.1, 1.2],\n",
    "        'multilabel': True if args.multilabel else False,\n",
    "        'mix_loss': args.mix_loss\n",
    "    }\n",
    "batch_augs = BatchAugs(ba_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#####################\n",
    "# losses            #\n",
    "#####################\n",
    "if args.loss_type == \"label_smooth\":\n",
    "    from modules.losses import LabelSmoothCrossEntropyLoss\n",
    "    criterion = LabelSmoothCrossEntropyLoss(smoothing=0.1, reduction='sum')\n",
    "elif args.loss_type == \"cross_entropy\":\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "elif args.loss_type == \"focal\":\n",
    "    from modules.losses import FocalLoss\n",
    "    criterion = FocalLoss()\n",
    "elif args.loss_type == 'bce':\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import lightning as L\n",
    "from workspace.datasets.batch_augs import BatchAugs\n",
    "from modules.soundnet import SoundNetRaw as SoundNet\n",
    "from utils.helper_funcs import accuracy\n",
    "\n",
    "class EAT(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(args)\n",
    "        ds_fac = np.prod(np.array(args.ds_factors)) * 4\n",
    "        self.model = SoundNet(\n",
    "                nf=args.nf,\n",
    "                dim_feedforward=args.dim_feedforward,\n",
    "                clip_length=args.seq_len // ds_fac,\n",
    "                embed_dim=args.emb_dim,\n",
    "                n_layers=args.n_layers,\n",
    "                nhead=args.n_head,\n",
    "                n_classes=args.n_classes,\n",
    "                factors=args.ds_factors,\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def augment_audio(audio):\n",
    "        transforms = args.augs_signal + args.augs_noise\n",
    "        for i in range(audio.shape[0]):\n",
    "            audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i])\n",
    "        return audio\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch['audio']\n",
    "        y = batch['label']\n",
    "        # augment x\n",
    "        # x = augment_audio(x)\n",
    "        x, targets, is_mixed = batch_augs(x, y) # TODO: removed epoch parameter\n",
    "        pred = self(x)\n",
    "        if is_mixed:\n",
    "            loss_cls = batch_augs.mix_loss(pred, targets, n_classes=args.n_classes,\n",
    "            pred_one_hot=args.multilabel)\n",
    "        else:\n",
    "            loss_cls = criterion(pred, y)\n",
    "        self.log('loss_cls', loss_cls)\n",
    "        return loss_cls\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch['audio']\n",
    "        y = batch['label']\n",
    "        pred = self(x)\n",
    "        loss_cls = criterion(pred, y)\n",
    "        acc = accuracy(pred, y, topk=(1,))[0]\n",
    "        self.log('acc', acc)\n",
    "        self.log('test_loss', loss_cls)\n",
    "        return loss_cls\n",
    "    \n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     loss = self.training_step(batch, batch_idx)\n",
    "    #     self.log('val_loss', loss)\n",
    "    #     return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if args.amp:\n",
    "            from torch.cuda.amp import GradScaler\n",
    "            scaler = GradScaler(init_scale=2**10)\n",
    "            eps = 1e-4\n",
    "        else:\n",
    "            scaler = None\n",
    "            eps = 1e-8\n",
    "        parameters = self.model.parameters()\n",
    "        return torch.optim.AdamW(parameters,\n",
    "                            lr=args.max_lr,\n",
    "                            betas=[0.9, 0.99],\n",
    "                            weight_decay=0,\n",
    "                            eps=eps)\n",
    "model = EAT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 90112])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 50])\n"
     ]
    }
   ],
   "source": [
    "# get one sample from datamodule\n",
    "# datamodule.prepare_data()\n",
    "datamodule.setup(stage='fit')\n",
    "sample = next(iter(datamodule.train_dataloader()))\n",
    "x = sample['audio']\n",
    "y = sample['label']\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "pred = model(x)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "\n",
    "trainer = L.Trainer(max_epochs=1000, accelerator='gpu', devices=args.gpus) # set devices to a list of GPU ids to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | SoundNetRaw | 5.2 M \n",
      "--------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.722    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113:  58%|█████▊    | 7/12 [00:06<00:04,  1.08it/s, v_num=6] "
     ]
    }
   ],
   "source": [
    "# start training \n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 16.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            acc            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           3.125           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     524.3833618164062     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           acc           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          3.125          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    524.3833618164062    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  4571           \t|  610.74         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  8.1768         \t|  10             \t|  81.768         \t|  13.388         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.33621        \t|  120            \t|  40.345         \t|  6.606          \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.3058         \t|  120            \t|  36.697         \t|  6.0086         \t|\n",
      "|  [LightningModule]EAT.optimizer_step                                                                                                                           \t|  0.30533        \t|  120            \t|  36.639         \t|  5.9992         \t|\n",
      "|  [_EvaluationLoop].test_next                                                                                                                                   \t|  1.1823         \t|  3              \t|  3.5468         \t|  0.58074        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.025646       \t|  120            \t|  3.0775         \t|  0.5039         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.021257       \t|  120            \t|  2.5508         \t|  0.41766        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.14826        \t|  10             \t|  1.4826         \t|  0.24276        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.0020738      \t|  120            \t|  0.24885        \t|  0.040746       \t|\n",
      "|  [LightningModule]EAT.optimizer_zero_grad                                                                                                                      \t|  0.00078643     \t|  120            \t|  0.094372       \t|  0.015452       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  0.00052184     \t|  123            \t|  0.064187       \t|  0.01051        \t|\n",
      "|  [LightningModule]EAT.transfer_batch_to_device                                                                                                                 \t|  0.00046359     \t|  123            \t|  0.057021       \t|  0.0093365      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.test_step                                                                                                                      \t|  0.018078       \t|  3              \t|  0.054233       \t|  0.0088799      \t|\n",
      "|  [LightningDataModule]ESC50DataModule.setup                                                                                                                    \t|  0.010678       \t|  2              \t|  0.021355       \t|  0.0034966      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.0019314      \t|  10             \t|  0.019314       \t|  0.0031624      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.00078994     \t|  10             \t|  0.0078994      \t|  0.0012934      \t|\n",
      "|  [LightningModule]EAT.configure_gradient_clipping                                                                                                              \t|  3.5336e-05     \t|  120            \t|  0.0042404      \t|  0.0006943      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.003715       \t|  1              \t|  0.003715       \t|  0.00060828     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.0033309      \t|  1              \t|  0.0033309      \t|  0.0005454      \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_start                                                                                                                       \t|  0.0031358      \t|  1              \t|  0.0031358      \t|  0.00051345     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  2.5705e-05     \t|  120            \t|  0.0030846      \t|  0.00050506     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_end                                                                                                                   \t|  0.00087912     \t|  3              \t|  0.0026374      \t|  0.00043183     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_start                                                                                                                 \t|  0.00083071     \t|  3              \t|  0.0024921      \t|  0.00040805     \t|\n",
      "|  [LightningDataModule]ESC50DataModule.train_dataloader                                                                                                         \t|  0.0021133      \t|  1              \t|  0.0021133      \t|  0.00034602     \t|\n",
      "|  [LightningDataModule]ESC50DataModule.test_dataloader                                                                                                          \t|  0.0015959      \t|  1              \t|  0.0015959      \t|  0.0002613      \t|\n",
      "|  [LightningModule]EAT.on_test_model_eval                                                                                                                       \t|  0.0013086      \t|  1              \t|  0.0013086      \t|  0.00021426     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.0011435      \t|  1              \t|  0.0011435      \t|  0.00018724     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_end                                                                                                                         \t|  0.00093091     \t|  1              \t|  0.00093091     \t|  0.00015242     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  6.0208e-06     \t|  120            \t|  0.0007225      \t|  0.0001183      \t|\n",
      "|  [LightningModule]EAT.on_test_model_train                                                                                                                      \t|  0.0006563      \t|  1              \t|  0.0006563      \t|  0.00010746     \t|\n",
      "|  [LightningModule]EAT.configure_optimizers                                                                                                                     \t|  0.00056631     \t|  1              \t|  0.00056631     \t|  9.2726e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  3.8533e-06     \t|  120            \t|  0.0004624      \t|  7.5712e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  3.8163e-06     \t|  120            \t|  0.00045796     \t|  7.4984e-05     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  3.0461e-06     \t|  120            \t|  0.00036553     \t|  5.9851e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  3.0377e-06     \t|  120            \t|  0.00036453     \t|  5.9686e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  2.8952e-06     \t|  120            \t|  0.00034742     \t|  5.6885e-05     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  2.6321e-06     \t|  120            \t|  0.00031586     \t|  5.1717e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  2.5215e-06     \t|  120            \t|  0.00030258     \t|  4.9544e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  2.5009e-06     \t|  120            \t|  0.00030011     \t|  4.9139e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  2.1778e-06     \t|  120            \t|  0.00026133     \t|  4.279e-05      \t|\n",
      "|  [LightningModule]EAT.on_after_backward                                                                                                                        \t|  2.0351e-06     \t|  120            \t|  0.00024421     \t|  3.9987e-05     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  1.96e-06       \t|  120            \t|  0.0002352      \t|  3.8511e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  1.7893e-06     \t|  120            \t|  0.00021471     \t|  3.5156e-05     \t|\n",
      "|  [LightningModule]EAT.on_after_batch_transfer                                                                                                                  \t|  1.7112e-06     \t|  123            \t|  0.00021048     \t|  3.4463e-05     \t|\n",
      "|  [LightningModule]EAT.on_before_batch_transfer                                                                                                                 \t|  1.7033e-06     \t|  123            \t|  0.00020951     \t|  3.4304e-05     \t|\n",
      "|  [LightningModule]EAT.on_before_optimizer_step                                                                                                                 \t|  1.7124e-06     \t|  120            \t|  0.00020549     \t|  3.3647e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  1.5783e-06     \t|  120            \t|  0.0001894      \t|  3.1012e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  1.5163e-06     \t|  120            \t|  0.00018196     \t|  2.9794e-05     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  1.4955e-06     \t|  120            \t|  0.00017946     \t|  2.9385e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  1.449e-06      \t|  120            \t|  0.00017388     \t|  2.847e-05      \t|\n",
      "|  [LightningModule]EAT.on_train_batch_end                                                                                                                       \t|  1.3995e-06     \t|  120            \t|  0.00016794     \t|  2.7498e-05     \t|\n",
      "|  [LightningModule]EAT.on_before_zero_grad                                                                                                                      \t|  1.3328e-06     \t|  120            \t|  0.00015994     \t|  2.6187e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  1.2129e-06     \t|  120            \t|  0.00014554     \t|  2.3831e-05     \t|\n",
      "|  [LightningModule]EAT.on_train_batch_start                                                                                                                     \t|  1.1862e-06     \t|  120            \t|  0.00014235     \t|  2.3308e-05     \t|\n",
      "|  [LightningModule]EAT.on_before_backward                                                                                                                       \t|  1.0373e-06     \t|  120            \t|  0.00012447     \t|  2.038e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  2.5359e-05     \t|  2              \t|  5.0717e-05     \t|  8.3043e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  4.4287e-06     \t|  10             \t|  4.4287e-05     \t|  7.2514e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  4.2039e-06     \t|  10             \t|  4.2039e-05     \t|  6.8833e-06     \t|\n",
      "|  [LightningModule]EAT.configure_callbacks                                                                                                                      \t|  1.6739e-05     \t|  2              \t|  3.3478e-05     \t|  5.4816e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  2.7808e-06     \t|  10             \t|  2.7808e-05     \t|  4.5533e-06     \t|\n",
      "|  [LightningModule]EAT.on_train_epoch_start                                                                                                                     \t|  2.6218e-06     \t|  10             \t|  2.6218e-05     \t|  4.2928e-06     \t|\n",
      "|  [LightningDataModule]ESC50DataModule.state_dict                                                                                                               \t|  2.5668e-06     \t|  10             \t|  2.5668e-05     \t|  4.2027e-06     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  1.8328e-06     \t|  10             \t|  1.8328e-05     \t|  3.001e-06      \t|\n",
      "|  [LightningDataModule]ESC50DataModule.prepare_data                                                                                                             \t|  9.069e-06      \t|  2              \t|  1.8138e-05     \t|  2.9699e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  1.809e-06      \t|  10             \t|  1.809e-05      \t|  2.962e-06      \t|\n",
      "|  [LightningModule]EAT.on_train_epoch_end                                                                                                                       \t|  1.735e-06      \t|  10             \t|  1.735e-05      \t|  2.8408e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  1.6699e-06     \t|  10             \t|  1.6699e-05     \t|  2.7342e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_end                                                                                                                      \t|  4.3497e-06     \t|  3              \t|  1.3049e-05     \t|  2.1366e-06     \t|\n",
      "|  [LightningModule]EAT.on_save_checkpoint                                                                                                                       \t|  1.1569e-06     \t|  10             \t|  1.1569e-05     \t|  1.8943e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  5.0049e-06     \t|  2              \t|  1.001e-05      \t|  1.639e-06      \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  4.8142e-06     \t|  2              \t|  9.6285e-06     \t|  1.5765e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_start                                                                                                                          \t|  8.8592e-06     \t|  1              \t|  8.8592e-06     \t|  1.4506e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_start                                                                                                                    \t|  2.9098e-06     \t|  3              \t|  8.7293e-06     \t|  1.4293e-06     \t|\n",
      "|  [LightningDataModule]ESC50DataModule.teardown                                                                                                                 \t|  4.2545e-06     \t|  2              \t|  8.509e-06      \t|  1.3932e-06     \t|\n",
      "|  [LightningModule]EAT.on_test_start                                                                                                                            \t|  8.319e-06      \t|  1              \t|  8.319e-06      \t|  1.3621e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  6.8997e-06     \t|  1              \t|  6.8997e-06     \t|  1.1297e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_end                                                                                                                    \t|  6.5891e-06     \t|  1              \t|  6.5891e-06     \t|  1.0789e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  6.1402e-06     \t|  1              \t|  6.1402e-06     \t|  1.0054e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_start     \t|  1.9396e-06     \t|  3              \t|  5.8189e-06     \t|  9.5277e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_start                                                                                                                 \t|  5.6797e-06     \t|  1              \t|  5.6797e-06     \t|  9.2997e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_end       \t|  1.8535e-06     \t|  3              \t|  5.5605e-06     \t|  9.1045e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  5.0403e-06     \t|  1              \t|  5.0403e-06     \t|  8.2529e-07     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  2.1951e-06     \t|  2              \t|  4.3903e-06     \t|  7.1885e-07     \t|\n",
      "|  [LightningModule]EAT.on_test_epoch_start                                                                                                                      \t|  4.1099e-06     \t|  1              \t|  4.1099e-06     \t|  6.7295e-07     \t|\n",
      "|  [LightningModule]EAT.configure_sharded_model                                                                                                                  \t|  2.0398e-06     \t|  2              \t|  4.0797e-06     \t|  6.6799e-07     \t|\n",
      "|  [LightningModule]EAT.on_test_batch_start                                                                                                                      \t|  1.3333e-06     \t|  3              \t|  4e-06          \t|  6.5495e-07     \t|\n",
      "|  [LightningModule]EAT.on_train_start                                                                                                                           \t|  3.9898e-06     \t|  1              \t|  3.9898e-06     \t|  6.5327e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  1.9649e-06     \t|  2              \t|  3.9297e-06     \t|  6.4344e-07     \t|\n",
      "|  [LightningModule]EAT.on_fit_end                                                                                                                               \t|  3.79e-06       \t|  1              \t|  3.79e-06       \t|  6.2057e-07     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  1.855e-06      \t|  2              \t|  3.7099e-06     \t|  6.0745e-07     \t|\n",
      "|  [LightningModule]EAT.on_test_batch_end                                                                                                                        \t|  1.2366e-06     \t|  3              \t|  3.7099e-06     \t|  6.0745e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  3.4701e-06     \t|  1              \t|  3.4701e-06     \t|  5.6818e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_end                                                                                                                   \t|  3.3602e-06     \t|  1              \t|  3.3602e-06     \t|  5.5019e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  3.3597e-06     \t|  1              \t|  3.3597e-06     \t|  5.5011e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  3.14e-06       \t|  1              \t|  3.14e-06       \t|  5.1413e-07     \t|\n",
      "|  [LightningModule]EAT.setup                                                                                                                                    \t|  1.5351e-06     \t|  2              \t|  3.0701e-06     \t|  5.0269e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_start           \t|  2.8997e-06     \t|  1              \t|  2.8997e-06     \t|  4.7478e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_end                                                                                                                            \t|  2.6803e-06     \t|  1              \t|  2.6803e-06     \t|  4.3887e-07     \t|\n",
      "|  [LightningModule]EAT.teardown                                                                                                                                 \t|  1.3001e-06     \t|  2              \t|  2.6003e-06     \t|  4.2576e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  2.2301e-06     \t|  1              \t|  2.2301e-06     \t|  3.6514e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  2.21e-06       \t|  1              \t|  2.21e-06       \t|  3.6186e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_start     \t|  1.98e-06       \t|  1              \t|  1.98e-06       \t|  3.242e-07      \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_start                                                                                                                    \t|  1.9399e-06     \t|  1              \t|  1.9399e-06     \t|  3.1764e-07     \t|\n",
      "|  [LightningModule]EAT.on_test_end                                                                                                                              \t|  1.749e-06      \t|  1              \t|  1.749e-06      \t|  2.8638e-07     \t|\n",
      "|  [LightningModule]EAT.prepare_data                                                                                                                             \t|  8.4518e-07     \t|  2              \t|  1.6904e-06     \t|  2.7677e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_start                                                                                                                  \t|  1.6904e-06     \t|  1              \t|  1.6904e-06     \t|  2.7677e-07     \t|\n",
      "|  [LightningModule]EAT.on_train_end                                                                                                                             \t|  1.5297e-06     \t|  1              \t|  1.5297e-06     \t|  2.5047e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  1.5204e-06     \t|  1              \t|  1.5204e-06     \t|  2.4894e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  1.5101e-06     \t|  1              \t|  1.5101e-06     \t|  2.4727e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_end                                                                                                                      \t|  1.4692e-06     \t|  1              \t|  1.4692e-06     \t|  2.4056e-07     \t|\n",
      "|  [LightningModule]EAT.on_fit_start                                                                                                                             \t|  1.4603e-06     \t|  1              \t|  1.4603e-06     \t|  2.3911e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_end       \t|  1.41e-06       \t|  1              \t|  1.41e-06       \t|  2.3087e-07     \t|\n",
      "|  [LightningModule]EAT.on_test_epoch_end                                                                                                                        \t|  1.3798e-06     \t|  1              \t|  1.3798e-06     \t|  2.2592e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_end             \t|  1.3602e-06     \t|  1              \t|  1.3602e-06     \t|  2.2271e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  1.3197e-06     \t|  1              \t|  1.3197e-06     \t|  2.1608e-07     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'acc': 3.125, 'test_loss': 524.3833618164062}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
