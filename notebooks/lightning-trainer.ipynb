{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# change path to workspace\n",
    "os.chdir('/workspace')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# reset gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramerers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "'''train'''\n",
    "parser.add_argument(\"--max_lr\", default=3e-4, type=float)\n",
    "parser.add_argument(\"--wd\", default=1e-5, type=float)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--run_name\", default=None, type=Path)\n",
    "parser.add_argument('--loss_type', default=\"label_smooth\", type=str)\n",
    "parser.add_argument('--n_epochs', default=None, type=int)\n",
    "parser.add_argument('--epoch_mix', default=None, type=int)\n",
    "parser.add_argument(\"--amp\", action='store_true')\n",
    "parser.add_argument(\"--filter_bias_and_bn\", action='store_true', default=True)\n",
    "parser.add_argument(\"--ext_pretrained\", default=None, type=str)\n",
    "parser.add_argument(\"--multilabel\", action='store_true')\n",
    "parser.add_argument('--save_path', default=None, type=Path)\n",
    "parser.add_argument('--load_path', default=None, type=Path)\n",
    "parser.add_argument('--scheduler', default=None, type=str)\n",
    "parser.add_argument('--augs_signal', nargs='+', type=str,\n",
    "                    default=['amp', 'neg', 'tshift', 'tmask', 'ampsegment', 'cycshift'])\n",
    "parser.add_argument('--augs_noise', nargs='+', type=str,\n",
    "                    default=['awgn', 'abgn', 'apgn', 'argn', 'avgn', 'aun', 'phn', 'sine'])\n",
    "# parser.add_argument('--augs_signal', nargs='+', type=str,\n",
    "#                     default=[])\n",
    "# parser.add_argument('--augs_noise', nargs='+', type=str,\n",
    "#                     default=[])\n",
    "parser.add_argument('--augs_mix', nargs='+', type=str, default=['mixup', 'timemix', 'freqmix', 'phmix'])\n",
    "parser.add_argument('--mix_loss', default='bce', type=str)\n",
    "parser.add_argument('--mix_ratio', default=1, type=float)\n",
    "parser.add_argument('--ema', default=0.995, type=float)\n",
    "parser.add_argument('--log_interval', default=100, type=int)\n",
    "parser.add_argument(\"--kd_model\", default=None, type=Path)\n",
    "parser.add_argument(\"--use_bg\", action='store_true', default=False)\n",
    "parser.add_argument(\"--resume_training\", action='store_true', default=False)\n",
    "parser.add_argument(\"--use_balanced_sampler\", action='store_true', default=False)\n",
    "'''common'''\n",
    "parser.add_argument('--local_rank', default=0, type=int)\n",
    "parser.add_argument('--gpu_ids', nargs='+', default=[0])\n",
    "parser.add_argument(\"--use_ddp\", action='store_true')\n",
    "parser.add_argument(\"--use_dp\", action='store_true')\n",
    "parser.add_argument('--save_interval', default=100, type=int)\n",
    "'''data'''\n",
    "parser.add_argument('--fold_id', default=1, type=int)\n",
    "parser.add_argument(\"--data_subtype\", default='balanced', type=str)\n",
    "parser.add_argument('--seq_len', default=90112, type=int)\n",
    "parser.add_argument('--dataset', default=\"esc50\", type=str)\n",
    "parser.add_argument('--n_classes', default=50, type=int)\n",
    "'''net'''\n",
    "parser.add_argument('--ds_factors', nargs='+', type=int, default=[4, 4, 4, 4])\n",
    "parser.add_argument('--n_head', default=8, type=int)\n",
    "parser.add_argument('--n_layers', default=4, type=int)\n",
    "parser.add_argument(\"--emb_dim\", default=128, type=int)\n",
    "parser.add_argument(\"--model_type\", default='SoundNetRaw', type=str)\n",
    "parser.add_argument(\"--nf\", default=16, type=int)\n",
    "parser.add_argument(\"--dim_feedforward\", default=512, type=int)\n",
    "parser.add_argument(\"--sampling_rate\", default=22050, type=int)\n",
    "'''system'''\n",
    "parser.add_argument('--data_dir', default='data/', type=Path)\n",
    "parser.add_argument('--data_path', default='/workspace/data/ESC-50-master', type=str)\n",
    "\n",
    "parser.add_argument('--gpus', type=list, default=[0])\n",
    "parser.add_argument('--num_workers', type=int, default=30)\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESC50 Dataset\n",
    "The ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.\n",
    "\n",
    "The dataset consists of 5-second-long recordings organized into 50 semantical classes.\n",
    "[Github](https://github.com/karolpiczak/ESC-50)\n",
    "\n",
    "[Huggingface](https://huggingface.co/datasets/ashraq/esc50) \"ashraq/esc50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "Prepare your dataset. All code that only need to be executed ones before training and results fit on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading data: 100%|██████████| 387M/387M [00:37<00:00, 10.2MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [00:35<00:00, 11.0MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [01:12<00:00, 72.90s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 574.40it/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:01<00:00, 1394.30 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:09<00:00, 206.15 examples/s]\n",
      "Saving the dataset (3/3 shards): 100%|██████████| 2000/2000 [00:00<00:00, 3339.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "def preprocess_audio(example):\n",
    "    audio = example['audio']\n",
    "    audio = audio['array']\n",
    "    if audio.shape[0] >= args.seq_len:\n",
    "        max_audio_start = audio.shape[0] - args.seq_len\n",
    "        audio_start = random.randint(0, max_audio_start)\n",
    "        audio = audio[audio_start : audio_start + args.seq_len]\n",
    "    else:\n",
    "        audio = F.pad(\n",
    "            audio, (0, args.seq_len - audio.size(0)), \"constant\"\n",
    "        ).data\n",
    "    example['audio'] = audio\n",
    "    return example\n",
    "\n",
    "esc50 = load_dataset(\"ashraq/esc50\", cache_dir=args.data_dir)\n",
    "esc50 = esc50.cast_column(\"audio\", Audio(sampling_rate=args.sampling_rate))\n",
    "# rename column target to label\n",
    "esc50 = esc50.rename_column(\"target\", \"label\")\n",
    "esc50 = esc50.map(preprocess_audio)\n",
    "esc50.save_to_disk(os.path.join(args.data_dir, 'esc50processed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import Audio\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model.augmentations.audio_augs import AudioAugs\n",
    "\n",
    "\n",
    "\n",
    "def train_transform(batch):\n",
    "    transforms = args.augs_signal + args.augs_noise\n",
    "    audio = torch.Tensor(batch['audio'])\n",
    "    if transforms is not None:\n",
    "        # check if audio has more then 1 dimension\n",
    "        if len(audio.shape) > 1:\n",
    "            # iterate over all dimensions\n",
    "            for i in range(audio.shape[0]):\n",
    "                audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i])\n",
    "        else:\n",
    "            batch['audio'] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio)      \n",
    "    batch['audio'] = audio.unsqueeze(1)\n",
    "    batch['label'] = torch.Tensor(batch['label']).long()\n",
    "    return batch\n",
    "\n",
    "def gpu_transforms(batch):\n",
    "    transforms = args.augs_signal + args.augs_noise\n",
    "    audio = batch['audio']\n",
    "    if transforms is not None:\n",
    "        # check if audio has more then 1 dimension\n",
    "        if len(audio.shape) > 1:\n",
    "            # iterate over all dimensions\n",
    "            for i in range(audio.shape[0]):\n",
    "                audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i][0])\n",
    "        else:\n",
    "            batch['audio'] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio)      \n",
    "    batch['audio'] = audio\n",
    "    return batch\n",
    "    \n",
    "def test_transform(batch):\n",
    "    batch['audio'] = torch.Tensor(batch['audio']).unsqueeze(1)\n",
    "    batch['label'] = torch.Tensor(batch['label']).long()\n",
    "    return batch\n",
    "\n",
    "class ESC50DataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: Path = args.data_dir):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    # called only within a single process on CPU but everytime trainer is envoked\n",
    "    # def prepare_data(self):\n",
    "\n",
    "    # run on each GPU\n",
    "    def setup(self, stage: str):\n",
    "        # load from disk\n",
    "        esc50 = load_from_disk(os.path.join(self.data_dir, 'esc50processed'))\n",
    "        esc50 = esc50.remove_columns(['filename', 'fold', 'category', 'esc10', 'src_file', 'take'])\n",
    "        # split into train, val, test\n",
    "        esc50 = esc50['train'].train_test_split(test_size=0.2, shuffle=True)\n",
    "        self.dataset_train = esc50['train']\n",
    "        # self.dataset_train = esc50['train'].with_format('torch', columns=['audio', 'label'])\n",
    "        self.dataset_test = esc50['test'].with_format('torch', columns=['audio', 'label'])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.dataset_train.set_transform(train_transform)\n",
    "        # self.dataset_train.set_transform(test_transform)\n",
    "        return DataLoader(self.dataset_train, batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        # generator=torch.Generator(device='cuda')\n",
    "        )\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.dataset_test.set_transform(test_transform)\n",
    "        return DataLoader(self.dataset_test, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        )\n",
    "    \n",
    "    # def on_after_batch_transfer(self, batch, dataloader_idx):\n",
    "    #     if self.trainer.training:\n",
    "    #         batch = gpu_transforms(batch)\n",
    "    #     return batch\n",
    "\n",
    "datamodule = ESC50DataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading data: 100%|██████████| 387M/387M [00:24<00:00, 15.7MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [00:24<00:00, 15.6MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:49<00:00, 49.30s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 553.63it/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:01<00:00, 1355.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['filename', 'fold', 'target', 'category', 'esc10', 'src_file', 'take', 'audio'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['filename', 'fold', 'target', 'category', 'esc10', 'src_file', 'take', 'audio'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "esc50 = load_dataset(\"ashraq/esc50\")\n",
    "esc50 = esc50.cast_column(\"audio\", Audio(sampling_rate=args.sampling_rate))\n",
    "# split into train, val, test\n",
    "esc50 = esc50['train'].train_test_split(test_size=0.2, shuffle=True)\n",
    "esc50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.augmentations.batch_augs import BatchAugs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "ba_params = {\n",
    "        'seq_len': args.seq_len,\n",
    "        'fs': args.sampling_rate,\n",
    "        'augs': args.augs_mix,\n",
    "        'device': device,\n",
    "        'mix_ratio': args.mix_ratio,\n",
    "        'batch_sz': args.local_rank,\n",
    "        'epoch_mix': args.epoch_mix,\n",
    "        'resample_factors': [0.8, 0.9, 1.1, 1.2],\n",
    "        'multilabel': True if args.multilabel else False,\n",
    "        'mix_loss': args.mix_loss\n",
    "    }\n",
    "batch_augs = BatchAugs(ba_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#####################\n",
    "# losses            #\n",
    "#####################\n",
    "if args.loss_type == \"label_smooth\":\n",
    "    from model.losses import LabelSmoothCrossEntropyLoss\n",
    "    criterion = LabelSmoothCrossEntropyLoss(smoothing=0.1, reduction='sum')\n",
    "elif args.loss_type == \"cross_entropy\":\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "elif args.loss_type == \"focal\":\n",
    "    from model.losses import FocalLoss\n",
    "    criterion = FocalLoss()\n",
    "elif args.loss_type == 'bce':\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import lightning as L\n",
    "from model.soundnet import SoundNetRaw as SoundNet\n",
    "from utils.helper_funcs import accuracy\n",
    "\n",
    "class EAT(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(args)\n",
    "        ds_fac = np.prod(np.array(args.ds_factors)) * 4\n",
    "        self.model = SoundNet(\n",
    "                nf=args.nf,\n",
    "                dim_feedforward=args.dim_feedforward,\n",
    "                clip_length=args.seq_len // ds_fac,\n",
    "                embed_dim=args.emb_dim,\n",
    "                n_layers=args.n_layers,\n",
    "                nhead=args.n_head,\n",
    "                n_classes=args.n_classes,\n",
    "                factors=args.ds_factors,\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def augment_audio(audio):\n",
    "        transforms = args.augs_signal + args.augs_noise\n",
    "        for i in range(audio.shape[0]):\n",
    "            audio[i] = AudioAugs(transforms, args.sampling_rate, p=0.5)(audio[i])\n",
    "        return audio\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch['audio']\n",
    "        y = batch['label']\n",
    "        # augment x\n",
    "        # x = augment_audio(x)\n",
    "        x, targets, is_mixed = batch_augs(x, y) # TODO: removed epoch parameter\n",
    "        pred = self(x)\n",
    "        if is_mixed:\n",
    "            loss_cls = batch_augs.mix_loss(pred, targets, n_classes=args.n_classes,\n",
    "            pred_one_hot=args.multilabel)\n",
    "        else:\n",
    "            loss_cls = criterion(pred, y)\n",
    "        self.log('loss_cls', loss_cls)\n",
    "        return loss_cls\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch['audio']\n",
    "        y = batch['label']\n",
    "        pred = self(x)\n",
    "        loss_cls = criterion(pred, y)\n",
    "        acc = accuracy(pred, y, topk=(1,))[0]\n",
    "        self.log('acc', acc)\n",
    "        self.log('test_loss', loss_cls)\n",
    "        return loss_cls\n",
    "    \n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     loss = self.training_step(batch, batch_idx)\n",
    "    #     self.log('val_loss', loss)\n",
    "    #     return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if args.amp:\n",
    "            from torch.cuda.amp import GradScaler\n",
    "            scaler = GradScaler(init_scale=2**10)\n",
    "            eps = 1e-4\n",
    "        else:\n",
    "            scaler = None\n",
    "            eps = 1e-8\n",
    "        parameters = self.model.parameters()\n",
    "        return torch.optim.AdamW(parameters,\n",
    "                            lr=args.max_lr,\n",
    "                            betas=[0.9, 0.99],\n",
    "                            weight_decay=0,\n",
    "                            eps=eps)\n",
    "model = EAT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 90112])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 50])\n"
     ]
    }
   ],
   "source": [
    "# get one sample from datamodule\n",
    "# datamodule.prepare_data()\n",
    "datamodule.setup(stage='fit')\n",
    "sample = next(iter(datamodule.train_dataloader()))\n",
    "x = sample['audio']\n",
    "y = sample['label']\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "pred = model(x)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "\n",
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=args.gpus, log_every_n_steps=10) # set devices to a list of GPU ids to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /workspace/lightning_logs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory data/esc50processed not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# start training \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py:941\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39msetup_environment()\n\u001b[1;32m    939\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[0;32m--> 941\u001b[0m call\u001b[39m.\u001b[39;49m_call_setup_hook(\u001b[39mself\u001b[39;49m)  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py:84\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpre_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     _call_lightning_datamodule_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39msetup\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage\u001b[39m=\u001b[39;49mfn)\n\u001b[1;32m     85\u001b[0m _call_callback_hooks(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[1;32m     86\u001b[0m _call_lightning_module_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py:165\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[1;32m    164\u001b[0m     \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 60\u001b[0m, in \u001b[0;36mESC50DataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, stage: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     59\u001b[0m     \u001b[39m# load from disk\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     esc50 \u001b[39m=\u001b[39m load_from_disk(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir, \u001b[39m'\u001b[39;49m\u001b[39mesc50processed\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     61\u001b[0m     esc50 \u001b[39m=\u001b[39m esc50\u001b[39m.\u001b[39mremove_columns([\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfold\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mesc10\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msrc_file\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     62\u001b[0m     \u001b[39m# split into train, val, test\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py:2227\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2224\u001b[0m     path_join \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin\n\u001b[1;32m   2226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fs\u001b[39m.\u001b[39mexists(dest_dataset_path):\n\u001b[0;32m-> 2227\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDirectory \u001b[39m\u001b[39m{\u001b[39;00mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2228\u001b[0m \u001b[39mif\u001b[39;00m fs\u001b[39m.\u001b[39misfile(path_join(dest_dataset_path, config\u001b[39m.\u001b[39mDATASET_INFO_FILENAME)) \u001b[39mand\u001b[39;00m fs\u001b[39m.\u001b[39misfile(\n\u001b[1;32m   2229\u001b[0m     path_join(dest_dataset_path, config\u001b[39m.\u001b[39mDATASET_STATE_JSON_FILENAME)\n\u001b[1;32m   2230\u001b[0m ):\n\u001b[1;32m   2231\u001b[0m     \u001b[39mreturn\u001b[39;00m Dataset\u001b[39m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory, storage_options\u001b[39m=\u001b[39mstorage_options)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory data/esc50processed not found"
     ]
    }
   ],
   "source": [
    "# start training \n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  9.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            acc            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         89.84375          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     138.3435516357422     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           acc           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        89.84375         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    138.3435516357422    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc': 89.84375, 'test_loss': 138.3435516357422}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
